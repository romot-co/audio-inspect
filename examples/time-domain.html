<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Audio Inspect - 時間領域特徴量デモ</title>
  <style>
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      margin: 0;
      padding: 20px;
      background-color: #f5f5f5;
    }
    
    .container {
      max-width: 1200px;
      margin: 0 auto;
      background: white;
      padding: 30px;
      border-radius: 10px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }
    
    h1 {
      color: #333;
      text-align: center;
      margin-bottom: 30px;
    }
    
    .controls {
      margin-bottom: 30px;
      text-align: center;
    }
    
    button {
      background: #007bff;
      color: white;
      border: none;
      padding: 10px 20px;
      margin: 5px;
      border-radius: 5px;
      cursor: pointer;
      font-size: 16px;
    }
    
    button:hover {
      background: #0056b3;
    }
    
    button:disabled {
      background: #ccc;
      cursor: not-allowed;
    }
    
    .feature-selector {
      margin: 20px 0;
      text-align: center;
    }
    
    select {
      padding: 8px 12px;
      font-size: 16px;
      border: 1px solid #ddd;
      border-radius: 4px;
    }
    
    .results {
      margin-top: 20px;
      padding: 20px;
      background: #f8f9fa;
      border-radius: 5px;
      border-left: 4px solid #007bff;
    }
    
    .result-item {
      margin: 10px 0;
      padding: 10px;
      background: white;
      border-radius: 3px;
      font-family: monospace;
    }
    
    .error {
      color: #dc3545;
      background: #f8d7da;
      border-color: #f5c6cb;
    }
    
    .status {
      margin: 10px 0;
      padding: 10px;
      border-radius: 3px;
    }
    
    .status.recording {
      background: #d4edda;
      color: #155724;
    }
    
    .status.processing {
      background: #fff3cd;
      color: #856404;
    }
    
    .canvas-container {
      margin: 20px 0;
      text-align: center;
    }
    
    canvas {
      border: 1px solid #ddd;
      background: white;
    }
    
    .metrics-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
      gap: 20px;
      margin: 20px 0;
    }
    
    .metric-card {
      background: white;
      padding: 20px;
      border-radius: 8px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
      text-align: center;
    }
    
    .metric-value {
      font-size: 2em;
      font-weight: bold;
      color: #007bff;
      margin: 10px 0;
    }
    
    .metric-label {
      color: #666;
      font-size: 0.9em;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>🎵 時間領域特徴量デモ</h1>
    
    <div class="controls">
      <button id="startBtn">🎤 解析開始</button>
      <button id="stopBtn" disabled>⏹️ 停止</button>
    </div>
    
    <div class="feature-selector">
      <label for="featureSelect">解析する特徴量:</label>
      <select id="featureSelect">
        <option value="getRMS">RMS (Root Mean Square)</option>
        <option value="getPeak">Peak Value</option>
        <option value="getPeakAmplitude">Peak Amplitude</option>
        <option value="getPeaks">Peaks Detection</option>
        <option value="getZeroCrossing">Zero Crossing Rate</option>
        <option value="getWaveform">Waveform Analysis</option>
      </select>
    </div>
    
    <div id="status" class="status">マイクアクセスを許可して「解析開始」ボタンを押してください</div>
    
    <div class="metrics-grid">
      <div class="metric-card">
        <div id="rmsValue" class="metric-value">0.000</div>
        <div class="metric-label">RMS</div>
      </div>
      <div class="metric-card">
        <div id="peakValue" class="metric-value">0.000</div>
        <div class="metric-label">Peak</div>
      </div>
      <div class="metric-card">
        <div id="zcrValue" class="metric-value">0.000</div>
        <div class="metric-label">ZCR</div>
      </div>
    </div>
    
    <div class="canvas-container">
      <canvas id="visualizer" width="800" height="300"></canvas>
    </div>
    
    <div class="results">
      <h3>解析結果 (最新10件)</h3>
      <div id="results"></div>
    </div>
  </div>

  <script type="module">
    class TimeDomainDemo {
      constructor() {
        this.audioContext = null;
        this.stream = null;
        this.source = null;
        this.audioInspectNode = null;
        this.isRecording = false;
        this.currentMetrics = {
          rms: 0,
          peak: 0,
          zcr: 0
        };
        
        this.setupEventListeners();
        this.setupCanvas();
      }
      
      setupEventListeners() {
        document.getElementById('startBtn').addEventListener('click', () => this.startAnalysis());
        document.getElementById('stopBtn').addEventListener('click', () => this.stopAnalysis());
        document.getElementById('featureSelect').addEventListener('change', () => this.changeFeature());
      }
      
      setupCanvas() {
        this.canvas = document.getElementById('visualizer');
        this.ctx = this.canvas.getContext('2d');
        this.clearCanvas();
      }
      
      clearCanvas() {
        this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
        this.ctx.fillStyle = '#f8f9fa';
        this.ctx.fillRect(0, 0, this.canvas.width, this.canvas.height);
        
        this.ctx.fillStyle = '#999';
        this.ctx.font = '24px Arial';
        this.ctx.textAlign = 'center';
        this.ctx.fillText('音声解析結果がここに表示されます', this.canvas.width / 2, this.canvas.height / 2);
      }
      
      async startAnalysis() {
        try {
          this.setStatus('初期化中...', 'processing');
          
          // オーディオコンテキストの作成
          this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
          
          // マイクアクセスの取得
          this.stream = await navigator.mediaDevices.getUserMedia({ 
            audio: {
              echoCancellation: false,
              noiseSuppression: false,
              autoGainControl: false
            } 
          });
          
          // MediaStreamSourceの作成
          this.source = this.audioContext.createMediaStreamSource(this.stream);
          
          // AudioWorkletの読み込み
          await this.loadAudioWorklet();
          
          // 解析開始
          await this.startFeatureAnalysis();
          
          // UI更新
          document.getElementById('startBtn').disabled = true;
          document.getElementById('stopBtn').disabled = false;
          this.setStatus('🔴 Recording and analyzing...', 'recording');
          
        } catch (error) {
          console.error('Failed to start analysis:', error);
          this.addError(`初期化失敗: ${error.message}`);
          this.setStatus('エラーが発生しました', 'error');
        }
      }
      
      async loadAudioWorklet() {
        try {
          // AudioWorkletProcessorを動的に作成
          const processorCode = `
class AudioInspectProcessor extends AudioWorkletProcessor {
  constructor() {
    super();
    this.bufferSize = 2048;
    this.buffer = new Float32Array(this.bufferSize);
    this.bufferIndex = 0;
    this.featureName = 'getRMS';
    
    this.port.onmessage = (event) => {
      if (event.data.type === 'setFeature') {
        this.featureName = event.data.featureName;
      }
    };
  }
  
  process(inputs, outputs, parameters) {
    const input = inputs[0];
    if (!input || !input[0]) return true;
    
    const inputData = input[0];
    
    // バッファにデータを蓄積
    for (let i = 0; i < inputData.length; i++) {
      this.buffer[this.bufferIndex] = inputData[i];
      this.bufferIndex = (this.bufferIndex + 1) % this.bufferSize;
      
      // バッファが満杯になったら解析実行
      if (this.bufferIndex === 0) {
        this.analyzeBuffer();
      }
    }
    
    return true;
  }
  
  analyzeBuffer() {
    let result;
    
    switch (this.featureName) {
      case 'getRMS':
        result = this.calculateRMS();
        break;
      case 'getPeak':
        result = this.calculatePeak();
        break;
      case 'getPeakAmplitude':
        result = this.calculatePeakAmplitude();
        break;
      case 'getZeroCrossing':
        result = this.calculateZeroCrossing();
        break;
      case 'getPeaks':
        result = this.findPeaks();
        break;
      case 'getWaveform':
        result = this.getWaveformData();
        break;
      default:
        result = this.calculateRMS();
    }
    
    this.port.postMessage({
      type: 'analysisResult',
      featureName: this.featureName,
      data: result,
      timestamp: currentTime,
      waveform: Array.from(this.buffer.slice(0, 200)) // 波形表示用
    });
  }
  
  calculateRMS() {
    let sum = 0;
    for (let i = 0; i < this.bufferSize; i++) {
      sum += this.buffer[i] * this.buffer[i];
    }
    return Math.sqrt(sum / this.bufferSize);
  }
  
  calculatePeak() {
    let peak = 0;
    for (let i = 0; i < this.bufferSize; i++) {
      const abs = Math.abs(this.buffer[i]);
      if (abs > peak) peak = abs;
    }
    return peak;
  }
  
  calculatePeakAmplitude() {
    return this.calculatePeak();
  }
  
  calculateZeroCrossing() {
    let crossings = 0;
    for (let i = 1; i < this.bufferSize; i++) {
      if ((this.buffer[i] >= 0) !== (this.buffer[i-1] >= 0)) {
        crossings++;
      }
    }
    return crossings / this.bufferSize;
  }
  
  findPeaks() {
    const peaks = [];
    for (let i = 1; i < this.bufferSize - 1; i++) {
      if (this.buffer[i] > this.buffer[i-1] && this.buffer[i] > this.buffer[i+1] && Math.abs(this.buffer[i]) > 0.1) {
        peaks.push({ index: i, value: this.buffer[i] });
      }
    }
    return peaks.slice(0, 10); // 上位10個
  }
  
  getWaveformData() {
    return {
      data: Array.from(this.buffer),
      sampleRate: sampleRate,
      duration: this.bufferSize / sampleRate
    };
  }
}

registerProcessor('audio-inspect-processor', AudioInspectProcessor);
          `;
          
          const blob = new Blob([processorCode], { type: 'application/javascript' });
          const workletUrl = URL.createObjectURL(blob);
          
          await this.audioContext.audioWorklet.addModule(workletUrl);
          URL.revokeObjectURL(workletUrl);
          
        } catch (error) {
          console.error('Failed to load AudioWorklet:', error);
          throw error;
        }
      }
      
      async startFeatureAnalysis() {
        const featureName = document.getElementById('featureSelect').value;
        
        // AudioWorkletNodeの作成
        this.audioInspectNode = new AudioWorkletNode(this.audioContext, 'audio-inspect-processor');
        
        // 特徴量設定
        this.audioInspectNode.port.postMessage({
          type: 'setFeature',
          featureName: featureName
        });
        
        // 結果受信ハンドラー
        this.audioInspectNode.port.onmessage = (event) => {
          if (event.data.type === 'analysisResult') {
            this.handleAnalysisResult(event.data);
          }
        };
        
        // オーディオグラフの接続
        this.source.connect(this.audioInspectNode);
        
        this.isRecording = true;
      }
      
      handleAnalysisResult(data) {
        // メトリクス更新
        if (data.featureName === 'getRMS') {
          this.currentMetrics.rms = data.data;
        } else if (data.featureName === 'getPeak' || data.featureName === 'getPeakAmplitude') {
          this.currentMetrics.peak = data.data;
        } else if (data.featureName === 'getZeroCrossing') {
          this.currentMetrics.zcr = data.data;
        }
        
        this.updateMetricsDisplay();
        
        // 波形表示
        if (data.waveform) {
          this.drawWaveform(data.waveform);
        }
        
        // 結果表示
        this.addResult(data);
      }
      
      updateMetricsDisplay() {
        document.getElementById('rmsValue').textContent = this.currentMetrics.rms.toFixed(3);
        document.getElementById('peakValue').textContent = this.currentMetrics.peak.toFixed(3);
        document.getElementById('zcrValue').textContent = this.currentMetrics.zcr.toFixed(3);
      }
      
      drawWaveform(waveformData) {
        const canvas = this.canvas;
        const ctx = this.ctx;
        
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        
        // 背景
        ctx.fillStyle = '#f8f9fa';
        ctx.fillRect(0, 0, canvas.width, canvas.height);
        
        // 中央線
        ctx.strokeStyle = '#ddd';
        ctx.lineWidth = 1;
        ctx.beginPath();
        ctx.moveTo(0, canvas.height / 2);
        ctx.lineTo(canvas.width, canvas.height / 2);
        ctx.stroke();
        
        // 波形描画
        ctx.strokeStyle = '#007bff';
        ctx.lineWidth = 2;
        ctx.beginPath();
        
        const step = canvas.width / waveformData.length;
        
        for (let i = 0; i < waveformData.length; i++) {
          const x = i * step;
          const y = (waveformData[i] + 1) * canvas.height / 2;
          
          if (i === 0) {
            ctx.moveTo(x, y);
          } else {
            ctx.lineTo(x, y);
          }
        }
        
        ctx.stroke();
      }
      
      changeFeature() {
        if (this.audioInspectNode && this.isRecording) {
          const featureName = document.getElementById('featureSelect').value;
          this.audioInspectNode.port.postMessage({
            type: 'setFeature',
            featureName: featureName
          });
        }
      }
      
      stopAnalysis() {
        if (this.audioInspectNode) {
          this.source.disconnect(this.audioInspectNode);
          this.audioInspectNode = null;
        }
        
        if (this.stream) {
          this.stream.getTracks().forEach(track => track.stop());
          this.stream = null;
        }
        
        if (this.audioContext) {
          this.audioContext.close();
          this.audioContext = null;
        }
        
        this.source = null;
        this.isRecording = false;
        
        // UI更新
        document.getElementById('startBtn').disabled = false;
        document.getElementById('stopBtn').disabled = true;
        this.setStatus('⏹️ 停止しました', 'info');
        this.clearCanvas();
      }
      
      addResult(data) {
        const resultsContainer = document.getElementById('results');
        const resultDiv = document.createElement('div');
        resultDiv.className = 'result-item';
        
        const timeStr = new Date().toLocaleTimeString();
        const featureStr = data.featureName;
        const valueStr = typeof data.data === 'object' ? JSON.stringify(data.data, null, 2) : data.data.toFixed(6);
        
        resultDiv.innerHTML = `
          <strong>${timeStr} - ${featureStr}:</strong><br>
          <pre>${valueStr}</pre>
        `;
        
        resultsContainer.appendChild(resultDiv);
        
        // 最新10件のみ表示
        while (resultsContainer.children.length > 10) {
          resultsContainer.removeChild(resultsContainer.firstChild);
        }
        
        resultDiv.scrollIntoView({ behavior: 'smooth' });
      }
      
      addError(message) {
        const resultsContainer = document.getElementById('results');
        const errorDiv = document.createElement('div');
        errorDiv.className = 'result-item error';
        errorDiv.innerHTML = `<strong>Error:</strong> ${message}`;
        resultsContainer.appendChild(errorDiv);
      }
      
      setStatus(message, type = 'info') {
        const statusDiv = document.getElementById('status');
        statusDiv.className = `status ${type}`;
        statusDiv.textContent = message;
      }
    }
    
    // デモ開始
    new TimeDomainDemo();
  </script>
</body>
</html>